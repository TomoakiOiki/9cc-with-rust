# 座学
#### BNFの続きから
  - `A = a_1`と`A = a_2`とあるときはどっちで展開しても良い
  - 生成規則の右辺は空でも良い(空を`ε`を使う)
  - 文字列はダブルクォートで囲う
    - 文字列は常に終端記号
  - EBNF
    - BNFに以下のルールを追加したもの
      - `A*`: Aの0回以上繰り返し
      - `A?`: A or ε
      - `A | B`: A or B
      - `(...)`: グループ化
      - 例: `("fizz" | "buzz")*`
    - EBNFはBNFでも表現できる
      - `A = a*` → `A = aA と A = ε`
      - `A = a?` → `A = a と A = ε`
      - `A = a | b` → `A = a と A = b`
      - `A = a (b_1 b_2...) c` → `A = aBc と B = b_1 b_2...`
#### 単純な生成規則
- 加減の生成規則
  - `expr = num ("+" num | "-" num)*`
```
expr → num → "1"

expr → num "+" num
     → "10" "+" "5"

expr → num "-" num "+" num
     → "42" "-" "30" "+" "2"
``` 
  - 入力に含まれるすべてのトークンを含んだ、文法に1対1でマッチした構文木を`具象構文木`という
  - EBNFでは文法は表現しても、計算順序などのルールは表現できない
    - 厳密にはEBNFでそこまで表現できるが、それによって定義される文法が複雑になりすぎてしまい、パーサーがうまく書けなくなるらしい
    - なので、文法としての厳密さと自然言語による補足のバランスが重要
#### 生成規則による演算子の優先順位の表現
- 下記のように先にmulというルールを入れてあげる
  - こうすることで木構造が1層深くなり、優先順位を表現できる
```
expr = mul ("+" mul | "-" mul)*
mul  = num ("*" num | "/" num)*
```
![image](https://user-images.githubusercontent.com/76932511/160813760-04d2f4e1-854d-4c91-a713-4fb078eb0d5c.png)
#### 再帰的な生成規則
- exprの子が更にexprを持つパターン
```
expr    = mul ("+" mul | "-" mul)*
mul     = primary ("*" primary | "/" primary)*
primary = num | "(" expr ")"
```
![image](https://user-images.githubusercontent.com/76932511/160813373-d5535457-8b83-4fbc-933f-356f68f07d90.png)
#### 再帰下降構文解析
- コンパイラがやりたいことは入力（プログラム）と同じ文字列を表現する構文木の構造を知ること
  - 再帰下降構文解析は規則から文にマッチする構文木を機械的に書くテクニック
- 基本戦略
  - 非終端記号を１つずつ関数にマッピングしていく
    - 上の例だと`expr,mul,primary`の3つの関数ができる
  - それぞれの関数はトークン列をパースする
  - というわけで実装に続く
- LL(n)パーサ
  - n個のトークンを先読みするパーサのこと
  - 今回実装しているのはLL(1)

#### スタックマシン
- LL(1)パーサによって抽象構文木はできた。じゃあここからどうやってアセンブリに変換するの？という話
  - 一旦立ち戻ってスタックマシンの理解
- スタックマシンの概念
  - スタックマシン：スタックをデータ保存領域として持っているコンピュータのこと
    - プッシュ、ポップの2つを基本操作とする
  - スタックマシンにおけるADD命令は、2つ要素をポップしてそれらを加算してスタックにプッシュすること
    - 加減乗除すべて同じ
  - 例: `2*3+4*5`
```
// 2*3を計算
PUSH 2
PUSH 3
MUL

// 4*5を計算
PUSH 4
PUSH 5
MUL

// 2*3 + 4*5を計算
ADD
```
- スタックマシンへのコンパイル
  - 抽象構文木 → スタックマシンコード
  - 木のコンパイル
    1. 左の部分木をコンパイル
    2. 右の部分木をコンパイル
    3. スタックの2つの値を、それらを加算した結果で置き換えるコードを出力
- 下記画像であれば
```
PUSH 2
PUSH 3
PUSH 4
MUL
ADD
```
![image](https://user-images.githubusercontent.com/76932511/160846729-bef4b1b1-1541-4922-a4ac-15045aa81877.png)

#### x86-64におけるスタックマシンの実現
- x86-64の演算は2つのレジスタ間に対して定義されていて、スタックのトップ2つに対して定義されているわけではない
  - つまり、レジスタマシンでスタックマシンをエミュレートしなくてはならない
  - スタックの先頭の要素を指すレジスタを１つ用意(スタックポインタと呼ぶ)
    - x86だと`RSPレジスタ`
  - 具体例
    - `2*3+4*5`
```
// 2*3を計算して結果をスタックにプッシュ
push 2
push 3

pop rdi
pop rax
mul rax, rdi
push rax

// 4*5を計算して結果をスタックにプッシュ
push 4
push 5

pop rdi
pop rax
mul rax, rdi
push rax

// スタックトップの2つの値を足す
// つまり2*3+4*5を計算する
pop rdi
pop rax
add rax, rdi
push rax
```
#### CISCとRISC
- どちらも命令セットの名前
- CISC
  - 機械語の演算がレジスタだけでなくメモリアドレスを指定することができる
  - 機械語命令の長さが可変であり、複雑な操作を1命令にまとめた命令が多くある
- RISC
  - CISCと思想が逆
  - 演算はレジスタのみ
  - 機械語命令の長さも固定で、簡単な命令のみに抑えられている
- じゃあどっちがデファクトになったか？
  - RISCとおもいきやCISC(というかx86-64)
  - シンプル故に高速化が容易だったRISCが主導権を握っていたが、Intelがx86命令をRISCに変換する技術を開発
  - これによりRISCが行った高速化テクニックがx86にも取り入れられ、表現力と速度を両立できるようになった
# 実装
- 再帰下降構文解析の実装
- 全体的なリファクタ
  - `Peekable<IntoIter<Token>>`を主体にループを回すように変更
# 感想
- 汎用的な文法の表現がわかってきた
- 今日は座学多めだったので明日は実装に集中
